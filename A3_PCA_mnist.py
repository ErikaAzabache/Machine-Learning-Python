# -*- coding: utf-8 -*-
"""Assignment_3_Import_MNIST.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1XOvc4xjK_Rolc5cCJHwlXdHxCUygvZ6a

# MNIST Assignment

### Import packages
"""

from google.colab import drive, auth
auth.authenticate_user()
import requests
gcloud_token = !gcloud auth print-access-token
drive.mount('/content/drive', force_remount=True)

import struct
import matplotlib.pyplot as plt
from array import array as pyarray
import numpy as np
from array import array
import pylab as pyl
import numpy.linalg as LA

"""# Function definitions

#### Data import
"""

MNIST_dir = '/content/drive/My Drive/Data/MNIST_dir'

def load_mnist(dataset="training", selecteddigits=range(10), path=MNIST_dir):

    #Check training/testing specification. MUST be "training" (default) or "testing"
    if dataset == "training":
        fname_digits = path + '/' + 'train-images.idx3-ubyte'
        fname_labels = path + '/' + 'train-labels.idx1-ubyte'
    elif dataset == "testing":
        fname_digits = path + '/' + 't10k-images.idx3-ubyte'
        fname_labels = path + '/' + 't10k-labels.idx1-ubyte'
    else:
        raise ValueError("dataset MUST be 'testing' or 'training'")
        
        
    #Import digits data
    digitsfileobject = open(fname_digits, 'rb')
    magic_nr, size, rows, cols = struct.unpack(">IIII", digitsfileobject.read(16))
    digitsdata = array("B", digitsfileobject.read())
    digitsfileobject.close()

    #Import label data
    labelsfileobject = open(fname_labels, 'rb')
    magic_nr, size = struct.unpack(">II", labelsfileobject.read(8))
    labelsdata=array("B",labelsfileobject.read())
    labelsfileobject.close()
    
    #Find indices of selected digits
    indices=[k for k in range(size) if labelsdata[k] in selecteddigits]
    N=len(indices)
    
    #Create empty arrays for X and T
    X = np.zeros((N, rows*cols), dtype=np.uint8)
    T = np.zeros((N), dtype=np.uint8)
    
    #Fill X from digitsdata
    #Fill T from labelsdata
    for i in range(N):
        X[i] = digitsdata[indices[i]*rows*cols:(indices[i]+1)*rows*cols]
        T[i] = labelsdata[indices[i]]
    
    return X,T

"""#### Display matrices as images"""

def vectortoimg(*args,width=28,size=1):
    """
    Example: vectortoimg(random.random(784)) or vectortoimg(random.random(784),arange(784))
    
    """
    n=len(args)
    fig = plt.figure()
    for i,arg in enumerate(args):
        plt.subplot(1,n,i+1)
        plt.imshow(arg.reshape(width, width),interpolation='None', cmap=pyl.cm.gray)
        plt.axis('off')
    fig.tight_layout(pad=0)
    fig.set_size_inches(w=n*size,h=size)
    plt.show()

"""# Main"""

[labeln,labelp]=[4,7]
X, T = load_mnist(dataset="training",selecteddigits=[labeln,labelp])
Xtest, Ttest = load_mnist(dataset="testing",selecteddigits=[labeln,labelp])

vectortoimg(X[0],X[1],X[-2],X[-3],size=3)

"""# XZCVP Procedure

This is done to reduce the 784-dimension X to a 2-dimension P (2D as asked). Once the reduction is done, we can apply what we know about Histogram/Bayesian classifiers to R.
"""

N=np.size(X,0); print(N)

d=np.size(X,1); print(d)

"""### X: {Nxd}"""

X.shape; print(X); print(np.all(X==0))

"""### Z: {Nxd}"""

mu=np.mean(X,axis=0);
mu.shape

"""Double checking that the values are within 0 and 255"""

print(np.min(mu,axis=0));
print(np.max(mu,axis=0))

Z=X-mu
Z.shape

"""Checking min and max values of Z (flatten). The mininum should be negative and the maximum positive"""

print(np.min(Z));
print(np.max(Z))

"""Checking that Z was calculated properly by getting the mean of Z, which should be a vector of zeroes"""

np.allclose(np.mean(Z, axis=0), np.zeros((N,d), dtype=np.uint8))

"""### C: {dxd}

Double checking that not all are zeroes
"""

C=np.cov(Z,rowvar=False);print(np.all(C==0))

C.shape

"""Double checking that C is symetric, which means C and CT should be equal"""

np.allclose(C,C.T)

"""### V: {dxd}"""

[lam, V]=LA.eigh(C)

lam.shape

V.shape

"""Figuring out if the eigenvectors are positioned in the rows or columns:"""

erow=V[-1,:]
np.allclose(np.dot(C,erow),lam[-1]*erow)

ecol=V[:,-1]
np.allclose(np.dot(C,ecol),lam[-1]*ecol)

"""It looks like the eigenvectors are arranged by columns. Now are they arranged in decreasing or increasing order of importance?"""

print(lam[0]);
print(lam[-1]);
lam.shape

"""It looks like it is in increasing order of importance. We would like to make it so it is in decreasing order of importance. To do this, we should reverse (flip) the order of the eigen vectors and values"""

lam=np.flipud(lam);V=np.flipud(V.T);
newrow=V[0,:]; #Check once again
np.allclose(np.dot(C,newrow),lam[0]*newrow)

"""### V-reduced {2xd}

Calculating Eigenvectors v1 and v2
"""

Vred = V[0:2,:]
v1 = Vred[0,:]
v2 = Vred[1,:]
print(Vred.shape,'\n', v1.shape,'\n', v2.shape)

"""Check for orthogonality of v1 and v2"""

np.allclose(np.dot(v1, v2), np.zeros((1,d)))

"""Check that v1 and v2 are properly normalized, if not, normalize"""

print(np.linalg.norm(v1));
print(np.linalg.norm(v2))

"""Cool, now we have V (and Vred) and can calculate the principal components

### P: {Nxd}
"""

P=np.dot(Z,V.T);print(P) #Principal components

Pred=np.dot(Z,Vred.T); print(Pred) #Principal components 2D reduction

print(P.shape); 
print(Pred.shape)

"""The mean of the P matrix should be around zero"""

np.allclose(np.mean(P, axis=0),np.zeros((N,d)))

np.allclose(np.mean(Pred, axis=0),np.zeros((N,2)))

"""### R: {Nxd}"""

R=np.dot(P,V);np.allclose(Z, R)

"""### Xrec: {Nxd}"""

Xrec = R + mu;np.allclose(X, Xrec)

"""The assignment asks for a reduction to a two dimensional approximation"""

Xrec2d=(np.dot(Pred,Vred))+mu;print(X, '\n\n', Xrec2d) #Reconstruction using 2 components

Xrec2d.shape

"""### Input/Output Functions:"""

with open('/content/drive/My Drive/Colab Notebooks/Assignment_3_Script.py') as infile:
    exec(infile.read())

excelfile = '/content/drive/My Drive/Data/Assignment_3_ Submission_Template.xlsx'

# indp=[k for k in range(len(T)) if T[k]==labelp]
# Np=len(indp); print(Np)

"""### Classifier Parameters"""

pmin=np.amin(Pred,axis=0)
p1min=pmin[0];
p2min=pmin[1];
print(pmin);

pmax=np.amax(Pred,axis=0)
p1max=pmax[0];
p2max=pmax[1];
print(pmax)

"""# Histogram Classifier"""

def Build2DHistogramClassifier(X,T,B,xmin,xmax,labeln,labelp):
    Hp=np.zeros([B,B]).astype('int8');
    Hn=np.zeros([B,B]).astype('int8');
    RC=(np.round(((B-1)*(X-xmin)/(xmax-xmin)))).astype('int8');
    for i,rc in enumerate(RC):
        if T[i]==labeln:
            Hn[rc[0],rc[1]]+=1;
        else:
            Hp[rc[0],rc[1]]+=1;
    return [Hn, Hp]

def Apply2DHistogramClassifier(queries,Hn,Hp,xmin,xmax,labeln,labelp):
    B=np.alen(Hn);
    RC=(np.round(((B-1)*(queries-xmin)/(xmax-xmin)))).astype('int8');
    countn=Hn[RC[:,0],RC[:,1]];
    countp=Hp[RC[:,0],RC[:,1]];
    resultlabel=np.full(np.alen(RC),"Indeterminate",dtype=object);
    resultprob=np.full(np.alen(RC),np.nan,dtype=object);
    indicesn=countn>countp;
    indicesp=countp>countn;
    resultlabel[indicesn]=labeln;
    resultlabel[indicesp]=labelp;
    probn=countn/(countn+countp);
    probp=countp/(countn+countp);
    resultprob[indicesn]=probn[indicesn];
    resultprob[indicesp]=probp[indicesp];
    return resultlabel, resultprob

"""In this case X (784 dimensions) in the histogram functions refers to Pred (2 dimensions)"""

B=32;
[Hn,Hp]=Build2DHistogramClassifier(Pred,T,B,pmin,pmax,labeln,labelp);

print(Hn.shape);
print(Hp.shape);

show2DHistograms(Hn, Hp)

"""Calculating Ptest from Xtest with Ptest=Ztest.VT"""

Ntest=np.size(Xtest,0);

Xtestp=Xtest[Ttest==labelp]
Ntestp=np.size(Xtestp,0);
idp = np.random.randint(Ntestp, size=1)
xp=Xtestp[idp,:];
truthp=T[idp]
print(T[idp]);
print(xp);
print(xp.shape)

vectortoimg(xp,size=3)

zp=xp-mu; print(zp.shape)

pp=np.dot(zp,Vred.T);
print(pp.shape)

rp=np.dot(pp,Vred)

xrecp=rp+mu

[resultlabelHp, resultprobHp]=Apply2DHistogramClassifier(pp,Hn,Hp,pmin,pmax,labeln,labelp);
print(resultlabelHp,resultprobHp)

Xtestn=Xtest[Ttest==labeln]
Ntestn=np.size(Xtestn,0);
idn = np.random.randint(Ntestn, size=1)
xn=Xtestn[idn,:];
truthn=T[idn]
print(T[idn])

vectortoimg(xn,size=3)

zn=xn-mu; print(zp.shape)

pn=np.dot(zn,Vred.T); print(pn)

rn=np.dot(pn,Vred)

xrecn=rn+mu

[resultlabelHn, resultprobHn]=Apply2DHistogramClassifier(pn,Hn,Hp,pmin,pmax,labeln,labelp);
print(resultlabelHn,resultprobHn)

"""#Bayesian Classifier"""

def Build2DBayesianClassifier(X,T,labeln,labelp):
    mubn=np.mean(X[T==labeln],axis=0);
    mubp=np.mean(X[T==labelp],axis=0);
    covbn=np.cov(X[T==labeln],rowvar=False);
    covbp=np.cov(X[T==labelp],rowvar=False);
    Nbn=len(T[T==labeln]);
    Nbp=len(T[T==labelp]);
    return [mubn,mubp,covbn,covbp,Nbn,Nbp]

def pdf(x,mu,sigma,d):
    dfact1=(2*np.pi)**d
    dfact2=np.linalg.det(sigma)
    fact=1/np.sqrt(dfact1*dfact2)
    xc=x-mu
    isigma=-0.5*np.linalg.inv(sigma)
    if len(np.shape(x)) == 1:
      return fact*np.exp(np.dot(np.dot(xc, isigma),xc))
    else:
      return fact\
        *np.exp(
            [np.dot(np.dot(v, isigma),v) for v in xc]
        )

def Apply2DBayesianClassifier(queries,d,mun,mup,cn,cp,Nn,Np,labeln,labelp):
    A=1;
    countn=Nn*A*pdf(queries,mun,cn,d)
    countp=Np*A*pdf(queries,mup,cp,d)
    resultlabel=np.full(np.alen(queries),"Indeterminate",dtype=object);
    resultprob=np.full(np.alen(queries),np.nan,dtype=object);
    indicesn=countn>countp;
    indicesp=countp>countn;
    resultlabel[indicesn]=labeln;
    resultlabel[indicesp]=labelp;
    probn=countn/(countn+countp);
    probp=countp/(countn+countp);
    resultprob[indicesn]=probn[indicesn];
    resultprob[indicesp]=probp[indicesp];
    return resultlabel, resultprob

[mun,mup,cn,cp,Nn,Np] = Build2DBayesianClassifier(Pred,T,labeln,labelp);
print(Nn);
print(Np);

print(mun.shape, mup.shape, cn.shape, cp.shape);

[resultlabelBn, resultprobBn]=Apply2DBayesianClassifier(pn,2,mun,mup,cn,cp,Nn,Np,labeln,labelp);
print(resultlabelBn,resultprobBn);

[resultlabelBp, resultprobBp]=Apply2DBayesianClassifier(pp,2,mun,mup,cn,cp,Nn,Np,labeln,labelp);
print(resultlabelBp,resultprobBp)

"""### Save Results"""

check_all_vars(all_vars)

excelfile = '/content/drive/My Drive/Data/Assignment_3_ Submission_Template.xlsx'

writeExcelData([mu],excelfile,'Results',2,2)
writeExcelData([v1],excelfile,'Results',3,2)
writeExcelData([v2],excelfile,'Results',4,2)
print("Written mu, v1, v2")

writeExcelData([Np,Nn],excelfile,'Results',6,2)
print("Written Np, Nn")

writeExcelData([mup,mun],excelfile,'Results',9,2)
print("Written mup, mun")

writeExcelData(cp,excelfile,'Results',12,2)
writeExcelData(cn,excelfile,'Results',14,2)
print("Written cp, cn")

writeExcelData([[p1min,p1max]],excelfile,'Results',17,2)
writeExcelData([[p2min,p2max]],excelfile,'Results',18,2)
print("Written p1min, p1max, p2min, p2max")

writeExcelData(Hp,excelfile,'Results',20,2)
writeExcelData(Hn,excelfile,'Results',53,2)
print("Written Hp, Hn")

writeExcelData(xp,excelfile,'Results',88,2)
writeExcelData(zp,excelfile,'Results',89,2)
writeExcelData(pp,excelfile,'Results',90,2)
writeExcelData(rp,excelfile,'Results',91,2)
writeExcelData(xrecp,excelfile,'Results',92,2)
print("Written xp, zp, rp, pp, xrecp")

writeExcelData(xn,excelfile,'Results',94,2)
writeExcelData(zn,excelfile,'Results',95,2)
writeExcelData(pn,excelfile,'Results',96,2)
writeExcelData(rn,excelfile,'Results',97,2)
writeExcelData(xrecn,excelfile,'Results',98,2)
print("Written xn, zn, rn, pn, xrecn")

writeExcelData([truthp],excelfile,'Results',102,2)
writeExcelData([resultlabelHp],excelfile,'Results',103,2)
writeExcelData([resultprobHp],excelfile,'Results',103,3)
writeExcelData([resultlabelBp],excelfile,'Results',104,2)
writeExcelData([resultprobBp],excelfile,'Results',104,3)
print("Written truthp, resultlabelHp, resultprobHp, resultlabelBp, resultprobBp")

writeExcelData([truthn],excelfile,'Results',106,2)
writeExcelData([resultlabelHn],excelfile,'Results',107,2)
writeExcelData([resultprobHn],excelfile,'Results',107,3)
writeExcelData([resultlabelBn],excelfile,'Results',108,2)
writeExcelData([resultprobBn],excelfile,'Results',108,3)
print("Written truthn, resultlabelHn, resultprobHn, resultlabelBn, resultprobBn")

# writeExcelData([accuracyH,accuracyB],excelfile,'Results',111,2)
# print("Written accuracyH, accuracyB")

closeExcelFile(excelfile)

print("Written everything!")

"""### Scatter Plot"""

# For best effect, points should not be drawn in sequence but in random order
np.random.seed(0)
randomorder=np.random.permutation(np.arange(len(T))) # Uncomment to draw points in random order
#randomorder=np.arange(len(T)) # Uncomment to draw points in sequence

# Set colors
opacity=0.25
cols=np.zeros((len(T),4))     # Initialize matrix to hold colors
cols[T==labeln]=[1,0,0,opacity] # Negative points are red (with opacity 0.25)
cols[T==labelp]=[0,1,0,opacity] # Positive points are green (with opacity 0.25)

# Draw scatter plot
fig = plt.figure(figsize=(10,10))
ax = fig.add_subplot(111, facecolor='black')
ax.scatter(P[randomorder,1],P[randomorder,0],s=50,linewidths=0,facecolors=cols[randomorder,:],marker="o");
ax.set_aspect('equal')

plt.gca().invert_yaxis()
plt.show()

"""### Accuracy

predicted label
"""

